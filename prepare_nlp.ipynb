{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c947bf7",
   "metadata": {},
   "source": [
    "# Prepare Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394575cc",
   "metadata": {},
   "source": [
    "Exercises\n",
    "\n",
    "The end result of this exercise should be a file named prepare.py that defines the requested functions.\n",
    "\n",
    "In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2de6c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import acquire as a\n",
    "import requests\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbde49d",
   "metadata": {},
   "source": [
    "# 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "* Lowercase everything\n",
    "* Normalize unicode characters\n",
    "* Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95caa92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(input_string):\n",
    "    '''\n",
    "    basice_clean function takes in a string and performs the following cleaning: lowercase, normalize characters\n",
    "    and replaces anything that ia a letter , number, whitespace or sigle quote\n",
    "    returns clean_string\n",
    "    '''\n",
    "    # takes original string and lowercase the string\n",
    "    clean_string = input_string.lower()\n",
    "    \n",
    "    # normalized the string\n",
    "    clean_string = unicodedata.normalize('NFKD', clean_string).encode('ascii','ignore').decode('utf-8')\n",
    "    \n",
    "    # remove anything that is not a through z, a number, a single quote, or whites\n",
    "    clean_string = re.sub(r\"[^a-z0-9'\\s]\", '', clean_string)\n",
    "    \n",
    "    return clean_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e243c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string = '1-034-@#$.32ksk|llkm fsadpfo-3-ljf &*^...hi mom...?/\\|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bb47ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Hey Amazon - my package never arrived https://www.amazon.com/gp/css/order-history?ref_=nav_orders_first PLEASE FIX ASAP! @AmazonHelp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cc020c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'103432kskllkm fsadpfo3ljf hi mom'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5647b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon  my package never arrived httpswwwamazoncomgpcssorderhistoryrefnavordersfirst please fix asap amazonhelp'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ccf40",
   "metadata": {},
   "source": [
    "# 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ecf8194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input_string,return_str = True):\n",
    "    '''\n",
    "    tokenize takes in a string and passes throug basic_clean function then tokenize all the words in the string\n",
    "    returns token_string\n",
    "    '''\n",
    "\n",
    "    # create tokenizer object\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "     \n",
    "    # apply token to string    \n",
    "    token_string  = tokenizer.tokenize(input_string, return_str=return_str)\n",
    "\n",
    "    \n",
    "    return token_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "acf6a3fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-034-@#$',\n",
       " '.32ksk',\n",
       " '&#124;',\n",
       " 'llkm',\n",
       " 'fsadpfo-3-ljf',\n",
       " '&*^',\n",
       " '...',\n",
       " 'hi',\n",
       " 'mom',\n",
       " '...',\n",
       " '?/\\\\',\n",
       " '&#124;']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(sample_string,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fccb2f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey Amazon - my package never arrived https://www.amazon.com/gp/css/order-history?ref_=nav_orders_first PLEASE FIX ASAP ! @AmazonHelp'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd4c5ba",
   "metadata": {},
   "source": [
    "# 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2da9c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(input_string):\n",
    "    '''\n",
    "    stem takes in a string \n",
    "    returns stem_string a stem version of string\n",
    "    '''\n",
    "    # create stemming object\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # stemming string\n",
    "    stem_string = [ps.stem(word) for word in input_string.split()]\n",
    "    # join stemmed string\n",
    "    stem_string = ' '.join(stem_string)\n",
    "    \n",
    "    return stem_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8f0683ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1-034-@#$.32ksk|llkm fsadpfo-3-ljf &*^...hi mom...?/\\\\|'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a24b1630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon my packag never arriv httpswwwamazoncomgpcssorderhistoryrefnavordersfirst pleas fix asap amazonhelp'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98992ec0",
   "metadata": {},
   "source": [
    "# 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cf710b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(input_string):\n",
    "    '''\n",
    "    lemmatize takes in a string \n",
    "    returns lemmas_string a lemmatize version of the string.\n",
    "    '''\n",
    "    \n",
    "    # create object\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    # apply lemmatizer to string\n",
    "    lemmas_string = [wnl.lemmatize(word) for word in input_string.split()]\n",
    "    lemmas_string = \" \".join(lemmas_string)\n",
    "    \n",
    "    return lemmas_string\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b19c4d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1-034-@#$.32ksk|llkm fsadpfo-3-ljf &*^...hi mom...?/\\\\|'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdcb11ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey amazon my package never arrived httpswwwamazoncomgpcssorderhistoryrefnavordersfirst please fix asap amazonhelp'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5553020",
   "metadata": {},
   "source": [
    "# 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ce4ee30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(input_string, extra_words = [],exclude_words = []):\n",
    "    '''\n",
    "    remove_stopwords takes in a string, optional extra_words as a list and exclude_words as a list\n",
    "    parameters with default  empty lists and returna string.\n",
    "    '''\n",
    "    \n",
    "    # ceate stopwords list\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    \n",
    "    # take out some words\n",
    "    stopwords_list = set(stopwords_list)-set(exclude_words)\n",
    "    \n",
    "    # words to be added\n",
    "    stopwords_list = stopwords_list.union(set(exclude_words))\n",
    "    \n",
    "    # split our document by spaces\n",
    "    words = input_string.split()\n",
    "    \n",
    "    # this is the stopwords applied(taken out of) the original text\n",
    "    new_string = [word for word in input_string.split() if word not in stopwords_list]\n",
    "    # join together\n",
    "    new_string = ' '.join(new_string)\n",
    "\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "56be327e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1-034-@#$.32ksk|llkm fsadpfo-3-ljf &*^...hi mom...?/\\\\|'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(sample_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c1945e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hey Amazon - package never arrived https://www.amazon.com/gp/css/order-history?ref_=nav_orders_first PLEASE FIX ASAP! @AmazonHelp'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7bfe1",
   "metadata": {},
   "source": [
    "# 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3aa06098",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame(a.inshort_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8f5fd2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moscow-Goa flight gets bomb threat, makes emer...</td>\n",
       "      <td>A Goa-bound flight from Russia's Moscow made a...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joshimath divided into 3 zones, govt says most...</td>\n",
       "      <td>Uttarakhand's Joshimath, where a majority of b...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which states have reported COVID-19 variant XB...</td>\n",
       "      <td>One new case of COVID-19 variant XBB.1.5, whic...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I decided to wear t-shirt till I shiver after ...</td>\n",
       "      <td>Congress leader Rahul Gandhi on Monday told re...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 children charred to death, 4 other siblings ...</td>\n",
       "      <td>At least two children were charred to death an...</td>\n",
       "      <td>national</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Weakening rupee could force us to raise domest...</td>\n",
       "      <td>Mercedes-Benz India Managing Director Santosh ...</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Volkswagen's India sales grow by 85% to 1.01 l...</td>\n",
       "      <td>Volkswagen's (VW) sales in India grew by 85.48...</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>India becomes world's 3rd largest auto market ...</td>\n",
       "      <td>India surpassed Japan to become the third-larg...</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Tesla reports record deliveries of 1.3 million...</td>\n",
       "      <td>Tesla on Monday reported that it delivered rec...</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Vehicle sales in India grow by 15% to 2.11 cro...</td>\n",
       "      <td>India's retail sales of overall vehicles witne...</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Moscow-Goa flight gets bomb threat, makes emer...   \n",
       "1    Joshimath divided into 3 zones, govt says most...   \n",
       "2    Which states have reported COVID-19 variant XB...   \n",
       "3    I decided to wear t-shirt till I shiver after ...   \n",
       "4    2 children charred to death, 4 other siblings ...   \n",
       "..                                                 ...   \n",
       "292  Weakening rupee could force us to raise domest...   \n",
       "293  Volkswagen's India sales grow by 85% to 1.01 l...   \n",
       "294  India becomes world's 3rd largest auto market ...   \n",
       "295  Tesla reports record deliveries of 1.3 million...   \n",
       "296  Vehicle sales in India grow by 15% to 2.11 cro...   \n",
       "\n",
       "                                               content    category  \n",
       "0    A Goa-bound flight from Russia's Moscow made a...    national  \n",
       "1    Uttarakhand's Joshimath, where a majority of b...    national  \n",
       "2    One new case of COVID-19 variant XBB.1.5, whic...    national  \n",
       "3    Congress leader Rahul Gandhi on Monday told re...    national  \n",
       "4    At least two children were charred to death an...    national  \n",
       "..                                                 ...         ...  \n",
       "292  Mercedes-Benz India Managing Director Santosh ...  automobile  \n",
       "293  Volkswagen's (VW) sales in India grew by 85.48...  automobile  \n",
       "294  India surpassed Japan to become the third-larg...  automobile  \n",
       "295  Tesla on Monday reported that it delivered rec...  automobile  \n",
       "296  India's retail sales of overall vehicles witne...  automobile  \n",
       "\n",
       "[297 rows x 3 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9deac6",
   "metadata": {},
   "source": [
    "# 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "89333646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start building our function:\n",
    "# first step: grab the article links:\n",
    "def get_blog_urls(base_url, header={'User-Agent': 'hamsandwich'}):\n",
    "    soup = BeautifulSoup(requests.get(url, headers=header).content)\n",
    "    return [link['href'] for link in soup.select('a.more-link')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4eb5db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_content(base_url):\n",
    "    blog_links = get_blog_urls(base_url)\n",
    "    all_blogs = []\n",
    "    for blog in blog_links:\n",
    "        blog_soup = soupify(\n",
    "            get(blog,\n",
    "                headers=header).content)\n",
    "        blog_content = {'title': blog_soup.select_one(\n",
    "            'h1.entry-title').text,\n",
    "        'content': blog_soup.select_one(\n",
    "            'div.entry-content').text.strip()}\n",
    "        all_blogs.append(blog_content)\n",
    "    return all_blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "52781969",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeup.com/blog/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a5f9e4fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://codeup.com/data-science/become-a-data-scientist/',\n",
       " 'https://codeup.com/employers/hiring-tech-talent/',\n",
       " 'https://codeup.com/cloud-administration/cap-funding-options/',\n",
       " 'https://codeup.com/dallas-info/it-professionals-dallas/',\n",
       " 'https://codeup.com/codeup-news/codeup-voted-1-technical-school-in-dfw/',\n",
       " 'https://codeup.com/tips-for-prospective-students/financing/codeups-scholarships/']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_blog_urls(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b02af5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = pd.DataFrame(codeup_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "932eecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Become a Data Scientist in 6 Months!</td>\n",
       "      <td>Are you feeling unfulfilled in your work but w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0  Become a Data Scientist in 6 Months!   \n",
       "\n",
       "                                             content  \n",
       "0  Are you feeling unfulfilled in your work but w...  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f6120d",
   "metadata": {},
   "source": [
    "# 8. For each dataframe, produce the following columns:\n",
    "\n",
    "* title to hold the title\n",
    "* original to hold the original article/post content\n",
    "* clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "* stemmed to hold the stemmed version of the cleaned data.\n",
    "* lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "44bcd8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.rename(columns={'content':'original'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ea2fb92c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df =news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6fcd26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean'] = df['original'].apply(basic_clean).apply(tokenize).apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c23a4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stemmed'] = df['clean'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9f067a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = df['clean'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3ef491c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>category</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moscow-Goa flight gets bomb threat, makes emer...</td>\n",
       "      <td>A Goa-bound flight from Russia's Moscow made a...</td>\n",
       "      <td>national</td>\n",
       "      <td>goabound flight russia ' moscow made emergency...</td>\n",
       "      <td>goabound flight russia ' moscow made emerg lan...</td>\n",
       "      <td>goabound flight russia ' moscow made emergency...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joshimath divided into 3 zones, govt says most...</td>\n",
       "      <td>Uttarakhand's Joshimath, where a majority of b...</td>\n",
       "      <td>national</td>\n",
       "      <td>uttarakhand ' joshimath majority buildings dev...</td>\n",
       "      <td>uttarakhand ' joshimath major build develop cr...</td>\n",
       "      <td>uttarakhand ' joshimath majority building deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which states have reported COVID-19 variant XB...</td>\n",
       "      <td>One new case of COVID-19 variant XBB.1.5, whic...</td>\n",
       "      <td>national</td>\n",
       "      <td>one new case covid19 variant xbb15 responsible...</td>\n",
       "      <td>one new case covid19 variant xbb15 respons ris...</td>\n",
       "      <td>one new case covid19 variant xbb15 responsible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I decided to wear t-shirt till I shiver after ...</td>\n",
       "      <td>Congress leader Rahul Gandhi on Monday told re...</td>\n",
       "      <td>national</td>\n",
       "      <td>congress leader rahul gandhi monday told repor...</td>\n",
       "      <td>congress leader rahul gandhi monday told repor...</td>\n",
       "      <td>congress leader rahul gandhi monday told repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 children charred to death, 4 other siblings ...</td>\n",
       "      <td>At least two children were charred to death an...</td>\n",
       "      <td>national</td>\n",
       "      <td>least two children charred death four others s...</td>\n",
       "      <td>least two children char death four other susta...</td>\n",
       "      <td>least two child charred death four others sust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Weakening rupee could force us to raise domest...</td>\n",
       "      <td>Mercedes-Benz India Managing Director Santosh ...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>mercedesbenz india managing director santosh i...</td>\n",
       "      <td>mercedesbenz india manag director santosh iyer...</td>\n",
       "      <td>mercedesbenz india managing director santosh i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Volkswagen's India sales grow by 85% to 1.01 l...</td>\n",
       "      <td>Volkswagen's (VW) sales in India grew by 85.48...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>volkswagen ' vw sales india grew 8548 101270 u...</td>\n",
       "      <td>volkswagen ' vw sale india grew 8548 101270 un...</td>\n",
       "      <td>volkswagen ' vw sale india grew 8548 101270 un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>India becomes world's 3rd largest auto market ...</td>\n",
       "      <td>India surpassed Japan to become the third-larg...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>india surpassed japan become thirdlargest auto...</td>\n",
       "      <td>india surpass japan becom thirdlargest auto ma...</td>\n",
       "      <td>india surpassed japan become thirdlargest auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Tesla reports record deliveries of 1.3 million...</td>\n",
       "      <td>Tesla on Monday reported that it delivered rec...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>tesla monday reported delivered record 13 mill...</td>\n",
       "      <td>tesla monday report deliv record 13 million ve...</td>\n",
       "      <td>tesla monday reported delivered record 13 mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Vehicle sales in India grow by 15% to 2.11 cro...</td>\n",
       "      <td>India's retail sales of overall vehicles witne...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>india ' retail sales overall vehicles witnesse...</td>\n",
       "      <td>india ' retail sale overal vehicl wit 1528 gro...</td>\n",
       "      <td>india ' retail sale overall vehicle witnessed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    Moscow-Goa flight gets bomb threat, makes emer...   \n",
       "1    Joshimath divided into 3 zones, govt says most...   \n",
       "2    Which states have reported COVID-19 variant XB...   \n",
       "3    I decided to wear t-shirt till I shiver after ...   \n",
       "4    2 children charred to death, 4 other siblings ...   \n",
       "..                                                 ...   \n",
       "292  Weakening rupee could force us to raise domest...   \n",
       "293  Volkswagen's India sales grow by 85% to 1.01 l...   \n",
       "294  India becomes world's 3rd largest auto market ...   \n",
       "295  Tesla reports record deliveries of 1.3 million...   \n",
       "296  Vehicle sales in India grow by 15% to 2.11 cro...   \n",
       "\n",
       "                                              original    category  \\\n",
       "0    A Goa-bound flight from Russia's Moscow made a...    national   \n",
       "1    Uttarakhand's Joshimath, where a majority of b...    national   \n",
       "2    One new case of COVID-19 variant XBB.1.5, whic...    national   \n",
       "3    Congress leader Rahul Gandhi on Monday told re...    national   \n",
       "4    At least two children were charred to death an...    national   \n",
       "..                                                 ...         ...   \n",
       "292  Mercedes-Benz India Managing Director Santosh ...  automobile   \n",
       "293  Volkswagen's (VW) sales in India grew by 85.48...  automobile   \n",
       "294  India surpassed Japan to become the third-larg...  automobile   \n",
       "295  Tesla on Monday reported that it delivered rec...  automobile   \n",
       "296  India's retail sales of overall vehicles witne...  automobile   \n",
       "\n",
       "                                                 clean  \\\n",
       "0    goabound flight russia ' moscow made emergency...   \n",
       "1    uttarakhand ' joshimath majority buildings dev...   \n",
       "2    one new case covid19 variant xbb15 responsible...   \n",
       "3    congress leader rahul gandhi monday told repor...   \n",
       "4    least two children charred death four others s...   \n",
       "..                                                 ...   \n",
       "292  mercedesbenz india managing director santosh i...   \n",
       "293  volkswagen ' vw sales india grew 8548 101270 u...   \n",
       "294  india surpassed japan become thirdlargest auto...   \n",
       "295  tesla monday reported delivered record 13 mill...   \n",
       "296  india ' retail sales overall vehicles witnesse...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "0    goabound flight russia ' moscow made emerg lan...   \n",
       "1    uttarakhand ' joshimath major build develop cr...   \n",
       "2    one new case covid19 variant xbb15 respons ris...   \n",
       "3    congress leader rahul gandhi monday told repor...   \n",
       "4    least two children char death four other susta...   \n",
       "..                                                 ...   \n",
       "292  mercedesbenz india manag director santosh iyer...   \n",
       "293  volkswagen ' vw sale india grew 8548 101270 un...   \n",
       "294  india surpass japan becom thirdlargest auto ma...   \n",
       "295  tesla monday report deliv record 13 million ve...   \n",
       "296  india ' retail sale overal vehicl wit 1528 gro...   \n",
       "\n",
       "                                            lemmatized  \n",
       "0    goabound flight russia ' moscow made emergency...  \n",
       "1    uttarakhand ' joshimath majority building deve...  \n",
       "2    one new case covid19 variant xbb15 responsible...  \n",
       "3    congress leader rahul gandhi monday told repor...  \n",
       "4    least two child charred death four others sust...  \n",
       "..                                                 ...  \n",
       "292  mercedesbenz india managing director santosh i...  \n",
       "293  volkswagen ' vw sale india grew 8548 101270 un...  \n",
       "294  india surpassed japan become thirdlargest auto...  \n",
       "295  tesla monday reported delivered record 13 mill...  \n",
       "296  india ' retail sale overall vehicle witnessed ...  \n",
       "\n",
       "[297 rows x 6 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf58f8",
   "metadata": {},
   "source": [
    "# 9 Ask yourself:\n",
    "\n",
    "* If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "* If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "* If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c7d1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5370ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
